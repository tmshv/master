{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание погоды\n",
    "## Coding Stream 2020.11.28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что мы хотим сделать?  \n",
    "У нас есть данные по погоде за несколько лет со многих метеостанций.  \n",
    "Мы попытаемся предсказать погоду на следующий день по предыдущим N дням с помощью линейной регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала качаем данные с ftp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import urllib\n",
    "from contextlib import closing\n",
    "\n",
    "with closing(urllib.request.urlopen('ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/2018.csv.gz')) as r:\n",
    "    with open('./2018.csv.gz', 'wb') as f:\n",
    "        shutil.copyfileobj(r, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Файлы довольно большие, поэтому мы не хотим их считывать с помощью pandas. Вместо этого мы используем средства самого Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формат следующий. Файл csv, каждая строка такая:   \n",
    "<id_станции>, <дата>, <метрика>, <значение>, <другие_параметры>  \n",
    "Нас интересуют первые 4 столбца"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы прочитаем все интересующие нас данные в память и выберем те метеостанции, которые вернули показания по средней дневной температуре и направлению ветра в каждый из дней года."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask – альтернатива pandas, позволяет делать многопоточные вычисления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "def days_in_year(year):\n",
    "    if year % 4 != 0:\n",
    "        return 365\n",
    "    if year % 400 == 0:\n",
    "        return 366\n",
    "    if year % 100 == 0:\n",
    "        return 365\n",
    "    return 366\n",
    "\n",
    "\n",
    "def parse_years(years):\n",
    "    \"\"\"\n",
    "    codes = {\n",
    "        code: {\n",
    "            'dt': {\n",
    "                'TAVG': float,\n",
    "                'SNWD': float\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result = {\n",
    "        code: [\n",
    "            (temp1, wind1),\n",
    "            (temp2, wind2),\n",
    "            ...\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for year in years:\n",
    "        codes = {}\n",
    "        for line in open('{year}.csv'.format(year=year), 'rt'):\n",
    "            if line and line[-1] == '\\n':\n",
    "                line = line[:-1]\n",
    "            data = line.split(',')\n",
    "            code, dt, metric, value = data[0:4]\n",
    "            if metric not in ['TAVG', 'SNWD']:\n",
    "                continue\n",
    "            if code not in codes:\n",
    "                codes[code] = {}\n",
    "            dates = codes[code]\n",
    "            if dt not in dates:\n",
    "                dates[dt] = {}\n",
    "            dates[dt][metric] = float(value) / 10\n",
    "        for code, dates in codes.items():\n",
    "            data_temp = [dates[dt]['TAVG'] for dt in sorted(dates.keys()) if 'TAVG' in dates[dt]]\n",
    "            data_wind = [dates[dt]['SNWD'] for dt in sorted(dates.keys()) if 'SNWD' in dates[dt]]\n",
    "            if len(data_temp) != days_in_year(year) or len(data_wind) != days_in_year(year):\n",
    "                continue\n",
    "            if code not in result:\n",
    "                result[code] = list(zip(data_temp, data_wind))\n",
    "            else:\n",
    "                result[code] += list(zip(data_temp, data_wind))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in generator:\n",
    "    i..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZA000067743,20161231,TAVG,272,H,,S,\n",
      "ZI000067775,20161231,TMAX,265,,,S,\n",
      "ZI000067775,20161231,PRCP,20,,,S,\n",
      "ZI000067775,20161231,TAVG,211,H,,S,\n",
      "ZI000067975,20161231,TMIN,190,,,S,\n",
      "ZI000067975,20161231,PRCP,109,,,S,\n",
      "ZI000067975,20161231,TAVG,221,H,,S,\n",
      "ZI000067983,20161231,TMAX,258,,,S,\n",
      "ZI000067983,20161231,PRCP,0,,,S,\n",
      "ZI000067983,20161231,TAVG,234,H,,S,\n"
     ]
    }
   ],
   "source": [
    "!tail -10 '2016.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4867760\n",
      "-rw-r--r--  1 lemhell  staff   1,2G 28 ноя 02:32 2016.csv\n",
      "-rw-r--r--  1 lemhell  staff   1,1G 28 ноя 02:38 2017.csv\n",
      "-rw-r--r--  1 lemhell  staff    17K 28 ноя 14:32 2020.11.28 Coding Stream.ipynb\n",
      "-rw-------@ 1 lemhell  staff   2,9K  9 июл 11:09 readme.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_data(data, window):\n",
    "    \"\"\"\n",
    "    Сюда приходит result\n",
    "    \n",
    "    yield создает генератор, который при каждом вызове (или итерации по нему) возвращает один объект за раз\n",
    "    Это полезно, когда у нас большие файлы, которые мы не хотим грузить в память\n",
    "    \"\"\"\n",
    "    for _, items in data.items():\n",
    "        for i in range(0, len(items) - window - 1):\n",
    "             yield items[i : i + window], items[i + window][0]\n",
    "\n",
    "def calc_mse(data, window, model):\n",
    "    result, count = 0.0, 0\n",
    "    for x, y in iterate_data(data, window):\n",
    "        result += ((model(x) - y)**2)\n",
    "        count += 1\n",
    "    return result / count\n",
    "\n",
    "\n",
    "def prepare_features(x):\n",
    "    return [x[i][0] for i in range(len(x))] + [x[i][1] for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression(data, window):\n",
    "    X, Y = [], []\n",
    "    for x, y in iterate_data(data, window):\n",
    "        X.append(prepare_features(x))\n",
    "        Y.append(y)\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(X, Y)\n",
    "    return regr\n",
    "\n",
    "\n",
    "def apply_regression(data, model):\n",
    "    return model.predict([prepare_features(data)])[0]\n",
    "\n",
    "\n",
    "def baseline_model(data):\n",
    "    # data is a list of tuples (temp, wind)\n",
    "    return data[-1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем наши данные  \n",
    "Данные для обучения и валидации не должны пересекаться – иначе это прямой путь к переобучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = parse_years([2016])\n",
    "test = parse_years([2017])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим окно, с которым мы будем обучать модель. Это будет количество дней (признаков), на которые мы будем смотреть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем метрики на обучении и валидации для нашей baseline-модели.  \n",
    "В качестве базовой модели выберем такую - будем всегда возвращать температуру за вчерашний день.  \n",
    "\n",
    "Почему мы делаем так: наша задача состоит в том, чтобы предсказать температуру на следующий день.  \n",
    "В качестве такого предсказания мы будем возвращать температуру за вчерашний день, так как обычно изменение температуры за соседние дни бывает не очень сильное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.72859275309986"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mse(train, window, baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.853850137207615"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mse(test, window, baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обучим нашу модель линейной регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_linear_regression(train, window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И посмотрим на результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.317883214892826"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mse(train, window, lambda x: apply_regression(x, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.746158385484083"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mse(test, window, lambda x: apply_regression(x, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось, что линейная регрессия справляется лучше, чем baseline-модель.  \n",
    "Также, метрики не сильно отличаются между обучением и валидацией. Это значит, что переобучения не произошло."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что, если мы возьмем другой размер окна?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 7.198350517415528\n",
      "MSE test 7.697311945722793\n"
     ]
    }
   ],
   "source": [
    "window = 30\n",
    "model = train_linear_regression(train, window)\n",
    "print(\"MSE train\", calc_mse(train, window, lambda x: apply_regression(x, model)))\n",
    "print(\"MSE test\", calc_mse(test, window, lambda x: apply_regression(x, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика на валидации заметно выше, чем на обучении. Похоже, мы встретились с переобучением.  \n",
    "Попробуем применить регуляризацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def train_ridge_regression(data, window, alpha=1.0):\n",
    "    X, Y = [], []\n",
    "    for x, y in iterate_data(data, window):\n",
    "        X.append(prepare_features(x))\n",
    "        Y.append(y)\n",
    "    regr = Ridge(alpha=alpha)\n",
    "    regr.fit(X, Y)\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 7.198350517690733\n",
      "MSE test 7.697312941918887\n"
     ]
    }
   ],
   "source": [
    "window = 30\n",
    "model = train_ridge_regression(train, window, alpha=10)\n",
    "print(\"MSE train\", calc_mse(train, window, lambda x: apply_regression(x, model)))\n",
    "print(\"MSE test\", calc_mse(test, window, lambda x: apply_regression(x, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 7.534483237026629\n",
      "MSE test 7.908413797271512\n"
     ]
    }
   ],
   "source": [
    "window = 7\n",
    "model = train_ridge_regression(train, window, alpha=100)\n",
    "print(\"MSE train\", calc_mse(train, window, lambda x: apply_regression(x, model)))\n",
    "print(\"MSE test\", calc_mse(test, window, lambda x: apply_regression(x, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем случайный лес (осторожно, обучается намного дольше регрессии):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def train_random_forest_regression(data, window, n_estimators=10, max_depth=None):\n",
    "    X, Y = [], []\n",
    "    for x, y in iterate_data(data, window):\n",
    "        X.append(prepare_features(x))\n",
    "        Y.append(y)\n",
    "    regr = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    regr.fit(X, Y)\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 0.7499780430456969\n",
      "MSE test 9.17987124192312\n"
     ]
    }
   ],
   "source": [
    "window = 30\n",
    "model = train_random_forest_regression(train, window)\n",
    "print(\"MSE train\", calc_mse(train, window, lambda x: apply_regression(x, model)))\n",
    "print(\"MSE test\", calc_mse(test, window, lambda x: apply_regression(x, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что модель очень сильно переобучилась. Попробуем ограничить глубину деревьев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 17.667707825236793\n",
      "MSE test 17.162301206039377\n"
     ]
    }
   ],
   "source": [
    "window = 30\n",
    "model = train_random_forest_regression(train, window, max_depth=2)\n",
    "print(\"MSE train\", calc_mse(train, window, lambda x: apply_regression(x, model)))\n",
    "print(\"MSE test\", calc_mse(test, window, lambda x: apply_regression(x, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переобучения больше нет, но результаты даже намного хуже, чем у baseline-модели. По-хорошему тут нужно запускать grid search на разные параметры, но это очень долго."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Над чем еще можно было бы поработать?\n",
    "\n",
    " * Использовать те метеостанции, которые не вернули данные за весь год - улучшит это обучение или ухудшит?\n",
    " * Учесть месяц/время года в качестве фичей\n",
    " * Учесть геопозицию метеостанции (это есть в соседних файлах на ftp, их можно скачать)\n",
    " * Что еще?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
