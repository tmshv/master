{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Война и мир"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Поздравляем с освоением важных для анализа данных структур и функций Python! Пришло время применить их на реальном проекте. Сегодня мы обратимся к классике: применим анализ данных к «Войне и миру» Льва Толстого!\n",
    "\n",
    "Текст произведения мы взяли в библиотеке [lib.ru](http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0073.shtml) и провели первоначальную обработку. Поскольку наша цель — обработка слов из этого произведения, мы разбили текст на слова и вывели каждое слово в отдельной строке. Кроме того, в местах, где начинаются главы, мы вывели строку `[new chapter]`.\n",
    "\n",
    "[Скачать предобработанный файл](https://lms.skillfactory.ru/assets/courseware/v1/4c5a80c60b5a00504915158c4e17fe20/asset-v1:SkillFactory+DS-MASTERS+01SEPT2020+type@asset+block/war_peace_processed.txt)\n",
    "\n",
    "Чтобы загрузить весь текст и разбить его на слова, в каждом задании используйте функцию `read_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция вернёт массив всех слов по порядку, а в местах начала новых глав будет строка `[new chapter]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "\n",
    "> Входные данные: строка `target_word`.\n",
    "\n",
    "Итак, начнём! Для начала посчитаем частоту использования отдельных слов в произведении. Для решения задачи воспользуемся уже знакомым нам словарём.\n",
    "\n",
    "**Задание**. Напишите программу, которая переберет все слова и занесет их в словарь (назвать его можете как угодно). Увеличивайте счётчик при добавлении каждого нового слова, чтобы посчитать сколько раз это слово встречается в тексте.\n",
    "\n",
    "**Подсказка**. Напоминаем, что метод `get` поможет проверить, какое значение соответствует ключу (слову) в словаре. Например, `words.get(word, 0)` вернёт либо значение из словаря, либо `0`, если соответствующее слово пока отсутствует.\n",
    "\n",
    "В качестве результата выведите, сколько раз слово `target_word` было найдено в тексте. Например, для `target_word = 'князь'` ответ будет `1289`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = {}\n",
    "for w in data:\n",
    "    c = word_count.get(w, 0)\n",
    "    c += 1\n",
    "    word_count[w] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1289"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_word = 'князь'\n",
    "word_count[target_word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "\n",
    "Входные данные: строка `target_word`.\n",
    "\n",
    "Пришло время познакомиться с понятием *document frequency*.\n",
    "\n",
    "*Document frequency* (для удобства сократим до *df*) — это доля документов, в которых встречается искомое слово. В нашем случае речь идёт не о документах, а о главах книги (выше мы писали, что в текстовом документе главы разделяются строкой `[new chapter]`).\n",
    "\n",
    "**Задание**. Напишите программу, которая посчитает *document frequency* для заданного слова `target_word` и выведите результат на экран."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подсказка**. Вычислить *df* можно по формуле:\n",
    "\n",
    "`number_of_documents_with_target_word / number_of_documents`\n",
    "\n",
    "- `number_of_documents` — общее количество глав\n",
    "- `number_of_documents_with_target_word` — количество глав, в которых встречается `target_word`\n",
    "\n",
    "Объясним на примере: наш текст состоит из `171` главы (`number_of_documents`), а слово *человек* встречается в `115` главах (`number_of_documents_with_target_word`).\n",
    "\n",
    "`df слова человек = 115 / 171 = 0.672514619883041`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_document_words(data):\n",
    "    doc = [{}]\n",
    "    word_count = [0]\n",
    "    current_chapter = 0\n",
    "    for w in data:\n",
    "        chapter = doc[-1]\n",
    "        if w == '[new chapter]':\n",
    "            doc.append({})\n",
    "            word_count.append(0)\n",
    "            continue\n",
    "        chapter[w] = chapter.get(w, 0) + 1\n",
    "        word_count[-1] += 1\n",
    "    return doc, word_count\n",
    "\n",
    "doc, word_count = calc_document_words(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_documents = len(doc)\n",
    "number_of_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_df(word):\n",
    "    count = 0\n",
    "    for chapter in doc:\n",
    "        if chapter.get(word):\n",
    "            count += 1\n",
    "    return count / len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.672514619883041"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_word = 'человек'\n",
    "calc_df(target_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "\n",
    "Сделаем следущий шаг: посчитаем частоту употребления отдельного слова в документе (*term frequency*, или *tf*).\n",
    "\n",
    "Проще всего объяснить, что такое *term frequency*, на примере:\n",
    "\n",
    "`tf слова война = количество раз, когда слово война встречается в тексте главы / количество всех слов в тексте главы`\n",
    "\n",
    "Попробуем посчитать частоту употребления слова *гостья* в 15-й главе (кстати, у нас главы нумеруются с 0). Слово гостья встречается в 15-й главе 10 раз, а общее количество слов — 1359.\n",
    "\n",
    "tf слова гостья в 15 главе = 101359 = 0.007358351729212656.\n",
    "\n",
    "**Задание**. Напишите программу, которая выведет частоту употребления заданного слова `target_word` в заданной главе `target_chapter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tf(word, chapter, word_count):\n",
    "    return chapter.get(word, 0) / word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007358351729212656"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_word = 'гостья'\n",
    "target_chapter = 15\n",
    "\n",
    "calc_tf(target_word, doc[target_chapter], word_count[target_chapter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4\n",
    "\n",
    "Входные данные:\n",
    "- строка `target_word`\n",
    "- число `target_chapter`\n",
    "\n",
    "Пришло время дать разъяснения: для чего мы делали вычисления выше и что нас ждет впереди?\n",
    "\n",
    "Если какое-то слово часто употребляется в документе, то, вероятно, этот документ что-то рассказывает о предмете/действии, описываемом этим словом. Скажем, если вы читаете книгу, в которой много раз употребляется слово *заяц*, то, вероятно, эта книга про зайцев.\n",
    "\n",
    "Однако, если вы возьмёте слово *и*, то оно будет встречаться почти в каждой книге много раз. Таким образом, если мы хотим найти наиболее значимые слова в книге, мы, с одной стороны, хотим найти наиболее частые слова, а с другой — убрать те, которые не несут важной информации, так как встречаются везде."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подсказка**. Такая задача хорошо решается с помощью `tf*idf` — статистической метрики для оценки важности слова в тексте. Другими словами, `tf*idf` — это «контрастность» слова в документе (насколько оно выделяется среди других слов).\n",
    "\n",
    "- `tf*idf = term frequency * inverse document frequency` \n",
    "- `tf` — это частотность термина, которая измеряет, насколько часто термин встречается в документе.\n",
    "- `idf` — это обратная документная частотность термина. Она измеряет непосредственно важность термина во всём множестве документов.\n",
    "\n",
    "Чтобы получить `idf`, необходимо поделить 1 на полученную в Задании 2 документную частоту (*df*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем использовать не сырые значения *tf* и *idf*, а их логарифмы, то есть `log(1+tf) * log(idf)`. Сейчас мы не будем заострять внимания на том, почему следует использовать именно логарифмы — это долгий разговор. Поговорим об этом в курсе *Математика и алгоритмы для машинного обучения*.\n",
    "\n",
    "В качестве примера измерим *tf*idf* слова *анна* в главе 4. Слово *анна* встречается в указанной главе 7 раз (`tf`), при этом в 4 главе 1060 слов (`chapter_size`), всего же слово *анна* упоминается в 32 главах (*df*) из 171 (`chapter_count`).\n",
    "\n",
    "Таким образом, *tf*idf* данного слова в данной главе будет равно `math.log(1 + tf / chapter_size) * math.log(1 / df)`, то есть\n",
    "0.011031063403921838.\n",
    "\n",
    "Задание. Напишите программу, которая выведет значение tf*idf для заданного слова target_word в заданной главе target_chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calc_tf_idf(word, chapter, word_count):\n",
    "    tf = calc_tf(word, chapter, word_count)\n",
    "    df = calc_df(word)\n",
    "    return math.log(1 + tf) * math.log(1 / df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011031063403921838"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_word = 'анна'\n",
    "target_chapter = 4\n",
    "calc_tf_idf(target_word, doc[target_chapter], word_count[target_chapter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5\n",
    "\n",
    "Теперь, когда мы умеем вычислять *tf*idf* для каждого слова в главе, мы можем найти те слова, которые являются самыми «контрастными» для данной главы, то есть они могут являться в своём роде заголовком для главы.\n",
    "\n",
    "**Задача**: напишите код, который выведет на экран через пробел три слова, имеющие самое высокое значение *tf*idf* в заданной главе `target_chapter` в порядке убывания *tf*idf*.\n",
    "\n",
    "Например, для 4 главы ответом будет: `павловна анна прядильной`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'павловна анна тетушку'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_chapter = 4\n",
    "chapter = doc[target_chapter]\n",
    "wc = word_count[target_chapter]\n",
    "words = chapter.keys()\n",
    "rated_words = [\n",
    "    (w, calc_tf_idf(w, chapter, wc))\n",
    "    for w in words\n",
    "]\n",
    "rated_words = sorted(rated_words, key=lambda x: x[1], reverse=True)\n",
    "top_words = rated_words[:3]\n",
    "result = ' '.join([n for n, r in top_words])\n",
    "result # тетушку == прядильной ¯\\_(ツ)_/¯"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
