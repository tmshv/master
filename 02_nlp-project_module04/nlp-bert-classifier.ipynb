{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Unit 3 - Text Classification\n\nUse BERT to classify texts\n\nAlso look at my solution using [LSTM](https://www.kaggle.com/update/sf-nlp-lstm-classifier)\n\nCompetition: https://www.kaggle.com/competitions/nlp-txt-classification\n\nBased on [this article](https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-23T19:29:23.101554Z","iopub.execute_input":"2022-04-23T19:29:23.102122Z","iopub.status.idle":"2022-04-23T19:29:23.129333Z","shell.execute_reply.started":"2022-04-23T19:29:23.102050Z","shell.execute_reply":"2022-04-23T19:29:23.128720Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nfrom typing import List, Dict, Any\n\n# import time\n\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\n\nfrom transformers import BertTokenizer\nfrom transformers import BertModel\n\nfrom tqdm import tqdm\n\n# import torch.nn.functional as F\n# from sklearn.model_selection import train_test_split\n# from sklearn.preprocessing import LabelEncoder\n# from keras.preprocessing.text import Tokenizer\n# from keras.preprocessing.sequence import pad_sequences\n\n# import matplotlib.pyplot as plt\n# import plotly.express as px\n# import scikitplot as skplt","metadata":{"execution":{"iopub.status.busy":"2022-04-23T22:40:02.084249Z","iopub.execute_input":"2022-04-23T22:40:02.086579Z","iopub.status.idle":"2022-04-23T22:40:02.091997Z","shell.execute_reply.started":"2022-04-23T22:40:02.086538Z","shell.execute_reply":"2022-04-23T22:40:02.091131Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = Path('/kaggle/input/nlp-txt-classification')\n\nSEED = 42\nNUM_CLASSES = 5\n# MAX_VOCAB_SIZE = 250000\nBATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2022-04-23T19:32:15.287663Z","iopub.execute_input":"2022-04-23T19:32:15.287942Z","iopub.status.idle":"2022-04-23T19:32:15.292178Z","shell.execute_reply.started":"2022-04-23T19:32:15.287910Z","shell.execute_reply":"2022-04-23T19:32:15.291141Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(DATA_PATH / 'test.csv')\ndf_test.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T19:33:28.678858Z","iopub.execute_input":"2022-04-23T19:33:28.679653Z","iopub.status.idle":"2022-04-23T19:33:28.718136Z","shell.execute_reply.started":"2022-04-23T19:33:28.679617Z","shell.execute_reply":"2022-04-23T19:33:28.717477Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(DATA_PATH / 'train.csv')\ndf = df[['Text', 'Sentiment']].dropna()\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T19:51:55.333217Z","iopub.execute_input":"2022-04-23T19:51:55.333474Z","iopub.status.idle":"2022-04-23T19:51:55.482558Z","shell.execute_reply.started":"2022-04-23T19:51:55.333444Z","shell.execute_reply":"2022-04-23T19:51:55.481783Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df['Sentiment'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T19:51:59.011422Z","iopub.execute_input":"2022-04-23T19:51:59.011676Z","iopub.status.idle":"2022-04-23T19:51:59.020495Z","shell.execute_reply.started":"2022-04-23T19:51:59.011647Z","shell.execute_reply":"2022-04-23T19:51:59.019760Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df.groupby(['Sentiment']).size().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T19:52:01.795280Z","iopub.execute_input":"2022-04-23T19:52:01.795763Z","iopub.status.idle":"2022-04-23T19:52:01.978154Z","shell.execute_reply.started":"2022-04-23T19:52:01.795601Z","shell.execute_reply":"2022-04-23T19:52:01.977499Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-cased')","metadata":{"execution":{"iopub.status.busy":"2022-04-23T19:35:57.481119Z","iopub.execute_input":"2022-04-23T19:35:57.481382Z","iopub.status.idle":"2022-04-23T19:35:58.059298Z","shell.execute_reply.started":"2022-04-23T19:35:57.481353Z","shell.execute_reply":"2022-04-23T19:35:58.058511Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"example_text = 'I will watch Memento tonight'\nbert_input = tokenizer(\n    example_text,\n    padding='max_length',\n    max_length = 10,\n    truncation=True,\n    return_tensors=\"pt\",\n)\n\nprint(bert_input['input_ids'])\nprint(bert_input['token_type_ids'])\nprint(bert_input['attention_mask'])","metadata":{"execution":{"iopub.status.busy":"2022-04-23T19:35:59.656400Z","iopub.execute_input":"2022-04-23T19:35:59.656647Z","iopub.status.idle":"2022-04-23T19:35:59.664593Z","shell.execute_reply.started":"2022-04-23T19:35:59.656619Z","shell.execute_reply":"2022-04-23T19:35:59.663771Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Here is the explanation of `BertTokenizer` parameters above:\n- `padding`: to pad each sequence to the maximum length that you specify.\n- `max_length`: the maximum length of each sequence. In this example we use 10, but for our actual dataset we will use 512, which is the maximum length of a sequence allowed for BERT.\n- `truncation`: if `True`, then the tokens in each sequence that exceed the maximum length will be truncated.\n- `return_tensors`: the type of tensors that will be returned. Since weâ€™re using PyTorch, then we use `pt`. If you use Tensorflow, then you need to use `tf`.","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\nlabels = {\n    'Extremely Negative': 0,\n    'Negative': 1,\n    'Neutral': 2,\n    'Positive': 3,\n    'Extremely Positive': 4,\n}\n\nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self, df):\n        self.labels = [\n            labels[label]\n            for label in df['Sentiment']\n        ]\n        self.texts = [\n            tokenizer(\n                text, \n                padding='max_length',\n                max_length = 512,\n                truncation=True,\n                return_tensors=\"pt\",\n            )\n            for text in df['Text']\n        ]\n\n    def classes(self):\n        return self.labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def get_batch_labels(self, idx):\n        # Fetch a batch of labels\n        return np.array(self.labels[idx])\n\n    def get_batch_texts(self, idx):\n        # Fetch a batch of inputs\n        return self.texts[idx]\n\n    def __getitem__(self, idx):\n        batch_texts = self.get_batch_texts(idx)\n        batch_y = self.get_batch_labels(idx)\n\n        return batch_texts, batch_y","metadata":{"execution":{"iopub.status.busy":"2022-04-23T19:42:03.982122Z","iopub.execute_input":"2022-04-23T19:42:03.982375Z","iopub.status.idle":"2022-04-23T19:42:04.563447Z","shell.execute_reply.started":"2022-04-23T19:42:03.982345Z","shell.execute_reply":"2022-04-23T19:42:04.562713Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"np.random.seed(112)\ndf_train, df_val = np.split(df.sample(frac=1, random_state=42), [int(.8*len(df))])\n\nprint(len(df_train), len(df_val))","metadata":{"execution":{"iopub.status.busy":"2022-04-23T19:56:46.827348Z","iopub.execute_input":"2022-04-23T19:56:46.827986Z","iopub.status.idle":"2022-04-23T19:56:46.843485Z","shell.execute_reply.started":"2022-04-23T19:56:46.827852Z","shell.execute_reply":"2022-04-23T19:56:46.842767Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class BertClassifier(nn.Module):\n    def __init__(self, num_classes:int, dropout:int=0.5):\n        super(BertClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-cased')\n        self.dropout = nn.Dropout(dropout)\n        self.linear = nn.Linear(768, num_classes)\n        self.relu = nn.ReLU()\n\n    def forward(self, input_id, mask):\n        _, pooled_output = self.bert(input_ids=input_id, attention_mask=mask,return_dict=False)\n        dropout_output = self.dropout(pooled_output)\n        linear_output = self.linear(dropout_output)\n        final_layer = self.relu(linear_output)\n\n        return final_layer","metadata":{"execution":{"iopub.status.busy":"2022-04-23T19:57:02.533155Z","iopub.execute_input":"2022-04-23T19:57:02.533412Z","iopub.status.idle":"2022-04-23T19:57:02.541125Z","shell.execute_reply.started":"2022-04-23T19:57:02.533384Z","shell.execute_reply":"2022-04-23T19:57:02.540284Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def train(model, train_data, val_data, learning_rate, epochs):\n    train = Dataset(train_data)\n    val = Dataset(val_data)\n    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = Adam(model.parameters(), lr= learning_rate)\n\n    if use_cuda:\n        model = model.cuda()\n        criterion = criterion.cuda()\n\n    for epoch_num in range(epochs):\n        total_acc_train = 0\n        total_loss_train = 0\n\n        for train_input, train_label in tqdm(train_dataloader):\n            train_label = train_label.to(device)\n            mask = train_input['attention_mask'].to(device)\n            input_id = train_input['input_ids'].squeeze(1).to(device)\n\n            output = model(input_id, mask)\n\n            batch_loss = criterion(output, train_label)\n            total_loss_train += batch_loss.item()\n\n            acc = (output.argmax(dim=1) == train_label).sum().item()\n            total_acc_train += acc\n\n            model.zero_grad()\n            batch_loss.backward()\n            optimizer.step()\n\n        total_acc_val = 0\n        total_loss_val = 0\n\n        with torch.no_grad():\n            for val_input, val_label in val_dataloader:\n                val_label = val_label.to(device)\n                mask = val_input['attention_mask'].to(device)\n                input_id = val_input['input_ids'].squeeze(1).to(device)\n\n                output = model(input_id, mask)\n\n                batch_loss = criterion(output, val_label)\n                total_loss_val += batch_loss.item()\n\n                acc = (output.argmax(dim=1) == val_label).sum().item()\n                total_acc_val += acc\n\n        print(' | '.join([\n            f'Epochs: {epoch_num + 1}',\n            f'Train Loss: {total_loss_train / len(train_data):.3f}',\n            f'Train Accuracy: {total_acc_train / len(train_data):.3f}',\n            f'Val Loss: {total_loss_val / len(val_data):.3f}',\n            f'Val Accuracy: {total_acc_val / len(val_data):.3f}',\n        ]))","metadata":{"execution":{"iopub.status.busy":"2022-04-23T19:58:32.197615Z","iopub.execute_input":"2022-04-23T19:58:32.198155Z","iopub.status.idle":"2022-04-23T19:58:32.210235Z","shell.execute_reply.started":"2022-04-23T19:58:32.198118Z","shell.execute_reply":"2022-04-23T19:58:32.209551Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"model = BertClassifier(num_classes=len(labels.keys()))","metadata":{"execution":{"iopub.status.busy":"2022-04-23T20:01:40.082930Z","iopub.execute_input":"2022-04-23T20:01:40.083177Z","iopub.status.idle":"2022-04-23T20:01:41.659571Z","shell.execute_reply.started":"2022-04-23T20:01:40.083148Z","shell.execute_reply":"2022-04-23T20:01:41.658773Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 1\nLR = 1e-6\n\ntrain(model, df_train, df_val, LR, EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T20:01:48.329587Z","iopub.execute_input":"2022-04-23T20:01:48.329852Z","iopub.status.idle":"2022-04-23T20:43:04.728883Z","shell.execute_reply.started":"2022-04-23T20:01:48.329821Z","shell.execute_reply":"2022-04-23T20:43:04.728075Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 2\nLR = 1e-6\n\ntrain(model, df_train, df_val, LR, EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T20:51:21.222675Z","iopub.execute_input":"2022-04-23T20:51:21.222951Z","iopub.status.idle":"2022-04-23T22:12:58.366064Z","shell.execute_reply.started":"2022-04-23T20:51:21.222920Z","shell.execute_reply":"2022-04-23T22:12:58.365394Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def flip_dict(x: Dict[Any, Any]) -> Dict[Any, Any]:\n    return dict([\n        (v, k)\n        for k, v in x.items()\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-04-23T22:40:06.944728Z","iopub.execute_input":"2022-04-23T22:40:06.945155Z","iopub.status.idle":"2022-04-23T22:40:06.950678Z","shell.execute_reply.started":"2022-04-23T22:40:06.945098Z","shell.execute_reply":"2022-04-23T22:40:06.949664Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def predict(model, text: str, labels: Dict[int, str]):\n    t = tokenizer(\n        text, \n        padding='max_length',\n        max_length = 512,\n        truncation=True,\n        return_tensors=\"pt\",\n    )\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n    if use_cuda:\n        model = model.cuda()\n    with torch.no_grad():\n        mask = t['attention_mask'].to(device)\n        input_id = t['input_ids'].squeeze(1).to(device)\n        output = model(input_id, mask)\n        pred = output.cpu().numpy()\n        idx = np.argmax(pred)\n        return labels[idx]","metadata":{"execution":{"iopub.status.busy":"2022-04-23T22:53:19.133434Z","iopub.execute_input":"2022-04-23T22:53:19.133684Z","iopub.status.idle":"2022-04-23T22:53:19.141687Z","shell.execute_reply.started":"2022-04-23T22:53:19.133656Z","shell.execute_reply":"2022-04-23T22:53:19.140771Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"x = df_test.loc[1, 'Text']\n\npred = predict(model, x, labels=flip_dict(labels))\n\nprint(x)\npred","metadata":{"execution":{"iopub.status.busy":"2022-04-23T22:42:03.584891Z","iopub.execute_input":"2022-04-23T22:42:03.585135Z","iopub.status.idle":"2022-04-23T22:42:03.629633Z","shell.execute_reply.started":"2022-04-23T22:42:03.585107Z","shell.execute_reply":"2022-04-23T22:42:03.628927Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"pred_labels = flip_dict(labels)\n\ndf_test['Sentiment'] = df_test['Text'].apply(lambda text: predict(model, text, labels=pred_labels))\ndf_test.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T22:45:35.037487Z","iopub.execute_input":"2022-04-23T22:45:35.037761Z","iopub.status.idle":"2022-04-23T22:47:16.338310Z","shell.execute_reply.started":"2022-04-23T22:45:35.037729Z","shell.execute_reply":"2022-04-23T22:47:16.337530Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"submission = df_test[['id', 'Sentiment']]\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T22:51:44.527838Z","iopub.execute_input":"2022-04-23T22:51:44.528102Z","iopub.status.idle":"2022-04-23T22:51:44.549261Z","shell.execute_reply.started":"2022-04-23T22:51:44.528073Z","shell.execute_reply":"2022-04-23T22:51:44.548587Z"},"trusted":true},"execution_count":80,"outputs":[]}]}