{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Flowerdata-module5 Classifier","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nimport torch\nfrom torch.nn import functional as F\n\nimport torchvision\nfrom torchvision import models\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\n\nimport pytorch_lightning as pl\n\nimport os\nimport random\nfrom tqdm import tqdm\nfrom copy import copy","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:29:26.210615Z","iopub.execute_input":"2022-04-20T22:29:26.211315Z","iopub.status.idle":"2022-04-20T22:29:29.444611Z","shell.execute_reply.started":"2022-04-20T22:29:26.211274Z","shell.execute_reply":"2022-04-20T22:29:29.443756Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\n%load_ext tensorboard\n\nprint(f'pl={pl.__version__}')\nprint(f'torch={torch.__version__}')\nprint(f'torchvision={torchvision.__version__}')","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:29:31.206673Z","iopub.execute_input":"2022-04-20T22:29:31.206942Z","iopub.status.idle":"2022-04-20T22:29:31.222793Z","shell.execute_reply.started":"2022-04-20T22:29:31.206913Z","shell.execute_reply":"2022-04-20T22:29:31.221895Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:29:33.581964Z","iopub.execute_input":"2022-04-20T22:29:33.582565Z","iopub.status.idle":"2022-04-20T22:29:33.622199Z","shell.execute_reply.started":"2022-04-20T22:29:33.582524Z","shell.execute_reply":"2022-04-20T22:29:33.621422Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input/flowerdata-module5/train/train'\n\nBATCH_SIZE = 16\nSEED = 20220421","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:29:40.496402Z","iopub.execute_input":"2022-04-20T22:29:40.496916Z","iopub.status.idle":"2022-04-20T22:29:40.501363Z","shell.execute_reply.started":"2022-04-20T22:29:40.496877Z","shell.execute_reply":"2022-04-20T22:29:40.500587Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dataset = ImageFolder(DATA_DIR)\ndataset","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:29:42.304799Z","iopub.execute_input":"2022-04-20T22:29:42.305070Z","iopub.status.idle":"2022-04-20T22:29:42.450908Z","shell.execute_reply.started":"2022-04-20T22:29:42.305040Z","shell.execute_reply":"2022-04-20T22:29:42.450187Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"sss = StratifiedShuffleSplit(n_splits=1, test_size=1000, train_size=None, random_state=SEED)\nX = [x[0] for x in dataset.samples]\ny = [x[1] for x in dataset.samples]\n\ntrain_idx, valid_idx = list(sss.split(X, y))[0]\nprint(len(train_idx), len(valid_idx))","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:29:44.412303Z","iopub.execute_input":"2022-04-20T22:29:44.413020Z","iopub.status.idle":"2022-04-20T22:29:44.431319Z","shell.execute_reply.started":"2022-04-20T22:29:44.412980Z","shell.execute_reply":"2022-04-20T22:29:44.430487Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_dataset = copy(dataset)\ntrain_dataset.samples = [dataset.samples[i] for i in train_idx]\ntrain_dataset.targets = [dataset.targets[i] for i in train_idx]\ntrain_dataset.imgs = train_dataset.samples\n\nvalid_dataset = copy(dataset)\nvalid_dataset.samples = [dataset.samples[i] for i in valid_idx]\nvalid_dataset.targets = [dataset.targets[i] for i in valid_idx]\nvalid_dataset.imgs = valid_dataset.samples\n\nprint(len(train_dataset), len(valid_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:29:46.434325Z","iopub.execute_input":"2022-04-20T22:29:46.435093Z","iopub.status.idle":"2022-04-20T22:29:46.445391Z","shell.execute_reply.started":"2022-04-20T22:29:46.435053Z","shell.execute_reply":"2022-04-20T22:29:46.444654Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def plot_samples(dataset, num_samples: int):\n    fig, axes = plt.subplots(1, num_samples, figsize=(16, 8))\n    for i in range(num_samples):\n        random_image, random_class = random.choice(dataset)\n        random_label = dataset.classes[random_class]\n        axes[i].imshow(random_image)\n        axes[i].set_title(random_label.replace(\"_\", \" \"))\n        axes[i].axis(\"off\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:29:50.857993Z","iopub.execute_input":"2022-04-20T22:29:50.858793Z","iopub.status.idle":"2022-04-20T22:29:50.866386Z","shell.execute_reply.started":"2022-04-20T22:29:50.858753Z","shell.execute_reply":"2022-04-20T22:29:50.865579Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"plot_samples(train_dataset, num_samples=10)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:29:51.834518Z","iopub.execute_input":"2022-04-20T22:29:51.835022Z","iopub.status.idle":"2022-04-20T22:29:52.622974Z","shell.execute_reply.started":"2022-04-20T22:29:51.834982Z","shell.execute_reply":"2022-04-20T22:29:52.620421Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"plot_samples(valid_dataset, num_samples=10)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:29:55.372285Z","iopub.execute_input":"2022-04-20T22:29:55.373038Z","iopub.status.idle":"2022-04-20T22:29:56.122440Z","shell.execute_reply.started":"2022-04-20T22:29:55.373000Z","shell.execute_reply":"2022-04-20T22:29:56.121721Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"normalize = transforms.Normalize(\n    mean=[0.485, 0.456, 0.406],\n    std=[0.229, 0.224, 0.225],\n)\n\ntrain_dataset.transform = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    normalize,\n])\n\nvalid_dataset.transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    normalize,\n])\n\ntest_transformations = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    normalize,\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:29:59.429840Z","iopub.execute_input":"2022-04-20T22:29:59.430586Z","iopub.status.idle":"2022-04-20T22:29:59.439277Z","shell.execute_reply.started":"2022-04-20T22:29:59.430540Z","shell.execute_reply":"2022-04-20T22:29:59.438497Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"NUM_WORKERS = 4 # or os.cpu_count()\n\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS\n)\n\nvalid_loader = torch.utils.data.DataLoader(\n    valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:30:01.374206Z","iopub.execute_input":"2022-04-20T22:30:01.375013Z","iopub.status.idle":"2022-04-20T22:30:01.379558Z","shell.execute_reply.started":"2022-04-20T22:30:01.374973Z","shell.execute_reply":"2022-04-20T22:30:01.378863Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class FlowersModel(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n\n        # используем предобученную модель ResNet-34\n        self.net = models.resnet34(pretrained=True)\n        # замораживаем веса\n        for parameter in self.net.parameters():\n            parameter.requres_grad = False\n        # заменяем полносвязный слой на новый под нужное количество классов\n        self.net.fc = torch.nn.Linear(512, len(train_dataset.classes))\n\n    def forward(self, x):\n        return self.net(x)\n\n    def training_step(self, batch, batch_nb):\n        images, target = batch\n        output = self(images)\n        # используем \"функциональную\" версию функции потерь вместо инстанцирования модуля\n        loss = F.cross_entropy(output, target)\n        with torch.no_grad():\n            top1 = torch.mean((output.argmax(1) == target).float()).item()\n\n        # логируем метрики — они будут как в прогрессбаре внизу, так и в отдельной директории\n        self.log('loss/train', loss, on_step=False, on_epoch=True)\n        self.log('top1/train', top1, on_step=False, on_epoch=True, prog_bar=True)\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        images, target = batch\n        output = self(images)\n        loss = loss = F.cross_entropy(output, target)\n        top1 = torch.mean((output.argmax(1) == target).float()).item()\n\n        self.log('loss/val', loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('top1/val', top1, on_step=False, on_epoch=True, prog_bar=True)\n\n    def configure_optimizers(self):\n        return torch.optim.SGD(self.net.parameters(), lr=1e-2, weight_decay=1e-4)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:30:32.332370Z","iopub.execute_input":"2022-04-20T22:30:32.332651Z","iopub.status.idle":"2022-04-20T22:30:32.344934Z","shell.execute_reply.started":"2022-04-20T22:30:32.332622Z","shell.execute_reply":"2022-04-20T22:30:32.344255Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = FlowersModel()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:30:35.626748Z","iopub.execute_input":"2022-04-20T22:30:35.627536Z","iopub.status.idle":"2022-04-20T22:30:36.064858Z","shell.execute_reply.started":"2022-04-20T22:30:35.627493Z","shell.execute_reply":"2022-04-20T22:30:36.064103Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"trainer = pl.Trainer(\n    gpus=1, # amount of GPU we wanted to use\n    max_epochs=30,\n    progress_bar_refresh_rate=1,\n)\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T22:31:05.926298Z","iopub.execute_input":"2022-04-20T22:31:05.926984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.keras.utils.image_dataset_from_directory(\n    DATA_DIR,\n    batch_size=BATCH_SIZE,\n    image_size=IMAGE_SIZE,\n#     label_mode='categorical',\n    shuffle=True,\n    seed=SEED,\n    validation_split=VALIDATION_SPLIT,\n    subset='training',\n)\nvalidation_dataset = tf.keras.utils.image_dataset_from_directory(\n    DATA_DIR,\n    batch_size=BATCH_SIZE,\n    image_size=IMAGE_SIZE,\n#     label_mode='categorical',\n    shuffle=True,\n    seed=SEED,\n    validation_split=VALIDATION_SPLIT,\n    subset='validation',\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = train_dataset.class_names\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_dataset.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        img = images[i].numpy()\n        label = labels[i].numpy()\n#         class_index = label.argmax()\n#         label = class_names[class_index]\n        plt.imshow(img.astype(\"uint8\"))\n        plt.title(label)\n        plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_CLASSES = len(train_dataset.class_names)\nprint(f'NUM_CLASSES={NUM_CLASSES}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n    tf.keras.layers.RandomRotation(0.2),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch, _ in train_dataset.take(1):\n  plt.figure(figsize=(10, 10))\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    augmented = data_augmentation(batch)\n    image = augmented[0]\n    plt.imshow(image / 255)\n    plt.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Model","metadata":{}},{"cell_type":"code","source":"preprocess_input = tf.keras.applications.efficientnet.preprocess_input","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = tf.keras.applications.EfficientNetB4(\n    input_shape=IMAGE_SIZE + (3,),\n    include_top=False,\n    weights='imagenet',\n)\nbase_model.trainable = False\n\ninputs = tf.keras.Input(shape=IMAGE_SIZE + (3,))\nx = data_augmentation(inputs)\n\n# x = layers.Rescaling(1.0 / 255)(x)\nx = preprocess_input(x)\n\nx = base_model(x, training=False)\n# x = global_average_layer(x)\n# x = tf.keras.layers.Dropout(0.2)(x)\n# outputs = prediction_layer(x)\n\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dropout(0.5)(x)\noutputs = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\ntf.keras.utils.plot_model(model, show_shapes = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stoping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_sparse_categorical_accuracy', \n#     monitor='val_categorical_accuracy', \n    mode='max', \n    verbose=1, \n    patience=7\n)\n\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath = \"best_model.hdf5\",\n    monitor='val_sparse_categorical_accuracy', \n#     monitor='val_categorical_accuracy', \n    mode='max', \n    verbose=1, \n    save_best_only=True\n)\n# keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n\nlearning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_sparse_categorical_accuracy', \n#     monitor='val_categorical_accuracy', \n    factor=0.6, \n    min_lr=1e-7\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configure fine tune parameters","metadata":{}},{"cell_type":"code","source":"base_model.trainable = True\n\nbase_model_layers = len(base_model.layers)\nno_fine_tune_layers = int(base_model_layers * 3/4)\n\nprint(f'{base_model_layers - no_fine_tune_layers} trainable of {base_model_layers} layers')\n\nfor layer in base_model.layers[:no_fine_tune_layers]:\n  layer.trainable =  False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(STEP),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"SparseCategoricalAccuracy\"]\n)\n# model.compile(\n#     optimizer=tf.keras.optimizers.Adam(STEP),\n#     loss=\"categorical_crossentropy\",\n#     metrics=[\"CategoricalAccuracy\"]\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 6\nhistory = model.fit(\n    train_dataset,\n    epochs=EPOCHS,\n    validation_data=validation_dataset,\n    callbacks=[early_stoping, learning_rate_reduction, model_checkpoint],\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class_index_to_label = [\n#     'DAISY',\n#     'DANDELION',\n#     'ROSE',\n#     'SUNFLOWER',\n#     'TULIP'\n# ]\n\n# validation_answers = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Flowers/sample_submission.csv')     #(PATH+'sample_submission.csv')\nmodel_answers = pd.DataFrame()\nfor PATH in submission['Id']:\n    img = tf.keras.preprocessing.image.load_img(\n        PATH, target_size=IMAGE_SIZE\n    )\n    img = np.asarray(img)/255\n    img_array = tf.keras.preprocessing.image.img_to_array(img)\n    img_array = tf.expand_dims(img_array, 0)\n\n    predictions = model.predict(img_array)\n    predicted_class_index = np.argmax(predictions, axis=1)[0]\n    category = predicted_class_index\n#     class_index_to_label[predicted_class_index]\n    model_answers = model_answers.append({'Id': PATH, 'Category': category}, ignore_index=True)\n\nmodel_answers","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(validation_dataset)\nprint(\"Accuracy\", accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss(history):\n  plt.plot(history.history['loss'], label='loss')\n  plt.plot(history.history['val_loss'], label='val_loss')\n  plt.ylim([0, 3])\n  plt.xlabel('Epoch')\n  plt.ylabel('Error [MPG]')\n  plt.legend()\n  plt.grid(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, path: str) -> int:\n    img = tf.keras.preprocessing.image.load_img(\n        path, target_size=IMAGE_SIZE\n    )\n    img = np.asarray(img) / 255\n    img_array = tf.keras.preprocessing.image.img_to_array(img)\n    img_array = tf.expand_dims(img_array, 0)\n\n    predictions = model.predict(img_array)\n#     return predictions/\n    return np.argmax(predictions[0])\n#     predicted_class_index = np.argmax(predictions, axis=1)[0]\n#     return int(predicted_class_index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = '/kaggle/input/flowerdata-module5/train/train/73/image_00431.jpg'\nx = tf.io.read_file(x)\nx = tf.image.decode_jpeg(x, channels=3)\nx = tf.image.convert_image_dtype(x, dtype=tf.float32)\nx = tf.image.resize(x, IMAGE_SIZE)\n# image = batch[0]\nx = tf.cast(tf.expand_dims(x, 0), tf.float32)\nx = model.predict(x)\ni = np.argmax(x[0])\n# x[0][i]\ni","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n\n# predictions = probability_model.predict(test_images)\n# predict(probability_model, '/kaggle/input/flowerdata-module5/test/test/image_00061.jpg')\npredict(model, '/kaggle/input/flowerdata-module5/test/test/image_00028.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/flowerdata-module5/sample_submission.csv')\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Category']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\nfor file in submission['Id']:\n    label = predict(model, f'/kaggle/input/flowerdata-module5/test/test/{file}')\n    df = df.append({\n        'Id': file,\n        'Category': label\n    }, ignore_index=True)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}