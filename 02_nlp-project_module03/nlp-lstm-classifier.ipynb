{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Unit 3 - Text Classification\n**Use recurrent neural networks to classify texts**\n \nhttps://www.kaggle.com/competitions/nlp-txt-classification","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-23T17:27:40.560396Z","iopub.execute_input":"2022-04-23T17:27:40.561059Z","iopub.status.idle":"2022-04-23T17:27:40.589375Z","shell.execute_reply.started":"2022-04-23T17:27:40.560936Z","shell.execute_reply":"2022-04-23T17:27:40.588700Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nfrom typing import List, Dict\n\nimport time\nimport re\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n# import torch.optim as optim\n# from torch.utils.data.dataset import random_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n# from nltk.tokenize import WordPunctTokenizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\n# from sklearn.metrics import f1_score\n# from tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport scikitplot as skplt","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:58:53.704605Z","iopub.execute_input":"2022-04-23T17:58:53.704859Z","iopub.status.idle":"2022-04-23T17:58:53.732348Z","shell.execute_reply.started":"2022-04-23T17:58:53.704830Z","shell.execute_reply":"2022-04-23T17:58:53.731683Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = Path('/kaggle/input/nlp-txt-classification')\n\nSEED = 42\nNUM_CLASSES = 5\nMAX_VOCAB_SIZE = 250000\nBATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:28:00.074227Z","iopub.execute_input":"2022-04-23T17:28:00.074492Z","iopub.status.idle":"2022-04-23T17:28:00.079491Z","shell.execute_reply.started":"2022-04-23T17:28:00.074457Z","shell.execute_reply":"2022-04-23T17:28:00.078672Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(DATA_PATH / 'train.csv')\ndf_train = df_train[['Text', 'Sentiment']]\ndf_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:28:03.861341Z","iopub.execute_input":"2022-04-23T17:28:03.861947Z","iopub.status.idle":"2022-04-23T17:28:04.112372Z","shell.execute_reply.started":"2022-04-23T17:28:03.861904Z","shell.execute_reply":"2022-04-23T17:28:04.111696Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_train['Sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:28:06.895605Z","iopub.execute_input":"2022-04-23T17:28:06.895861Z","iopub.status.idle":"2022-04-23T17:28:06.915788Z","shell.execute_reply.started":"2022-04-23T17:28:06.895830Z","shell.execute_reply":"2022-04-23T17:28:06.915025Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"See at null values","metadata":{}},{"cell_type":"code","source":"df_train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:28:09.298910Z","iopub.execute_input":"2022-04-23T17:28:09.299542Z","iopub.status.idle":"2022-04-23T17:28:09.316614Z","shell.execute_reply.started":"2022-04-23T17:28:09.299499Z","shell.execute_reply":"2022-04-23T17:28:09.315828Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Several nulls found. Ignore them","metadata":{}},{"cell_type":"code","source":"df_train = df_train.dropna()\ndf_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:28:11.333078Z","iopub.execute_input":"2022-04-23T17:28:11.333570Z","iopub.status.idle":"2022-04-23T17:28:11.352666Z","shell.execute_reply.started":"2022-04-23T17:28:11.333533Z","shell.execute_reply":"2022-04-23T17:28:11.351918Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"See at the balance of classes","metadata":{}},{"cell_type":"code","source":"count_df = df_train.groupby('Sentiment')\\\n    .aggregate({'Text': 'count'})\\\n    .reset_index()\\\n    .sort_values('Text', ascending=False)\npx.bar(count_df, x='Sentiment', y='Text')","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:28:14.373272Z","iopub.execute_input":"2022-04-23T17:28:14.375161Z","iopub.status.idle":"2022-04-23T17:28:15.160646Z","shell.execute_reply.started":"2022-04-23T17:28:14.375112Z","shell.execute_reply":"2022-04-23T17:28:15.159990Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(DATA_PATH / 'test.csv')\ndf_test.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:28:26.597227Z","iopub.execute_input":"2022-04-23T17:28:26.597903Z","iopub.status.idle":"2022-04-23T17:28:26.636185Z","shell.execute_reply.started":"2022-04-23T17:28:26.597859Z","shell.execute_reply":"2022-04-23T17:28:26.635527Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"replacement_dict = {\n    \"ain't\": \"is not\",\n    \"aren't\": \"are not\",\n    \"can't\": \"cannot\",\n    \"'cause\": \"because\",\n    \"could've\": \"could have\",\n    \"couldn't\": \"could not\",\n    \"didn't\": \"did not\",\n    \"doesn't\": \"does not\",\n    \"don't\": \"do not\",\n    \"hadn't\": \"had not\",\n    \"hasn't\": \"has not\",\n    \"haven't\": \"have not\",\n    \"he'd\": \"he would\",\n    \"he'll\": \"he will\",\n    \"he's\": \"he is\",\n    \"how'd\": \"how did\",\n    \"how'd'y\": \"how do you\",\n    \"how'll\": \"how will\",\n    \"how's\": \"how is\", \n    \"I'd\": \"I would\",\n    \"I'd've\": \"I would have\",\n    \"I'll\": \"I will\",\n    \"I'll've\": \"I will have\",\n    \"I'm\": \"I am\",\n    \"I've\": \"I have\",\n    \"i'd\": \"i would\",\n    \"i'd've\": \"i would have\",\n    \"i'll\": \"i will\",\n    \"i'll've\": \"i will have\",\n    \"i'm\": \"i am\",\n    \"i've\": \"i have\",\n    \"isn't\": \"is not\",\n    \"it'd\": \"it would\",\n    \"it'd've\": \"it would have\",\n    \"it'll\": \"it will\",\n    \"it'll've\": \"it will have\",\n    \"it's\": \"it is\",\n    \"let's\": \"let us\",\n    \"ma'am\": \"madam\",\n    \"mayn't\": \"may not\",\n    \"might've\": \"might have\",\n    \"mightn't\": \"might not\",\n    \"mightn't've\": \"might not have\",\n    \"must've\": \"must have\",\n    \"mustn't\": \"must not\",\n    \"mustn't've\": \"must not have\",\n    \"needn't\": \"need not\",\n    \"needn't've\": \"need not have\",\n    \"o'clock\": \"of the clock\",\n    \"oughtn't\": \"ought not\",\n    \"oughtn't've\": \"ought not have\",\n    \"shan't\": \"shall not\",\n    \"sha'n't\": \"shall not\",\n    \"shan't've\": \"shall not have\",\n    \"she'd\": \"she would\",\n    \"she'd've\": \"she would have\",\n    \"she'll\": \"she will\",\n    \"she'll've\": \"she will have\",\n    \"she's\": \"she is\",\n    \"should've\": \"should have\",\n    \"shouldn't\": \"should not\",\n    \"shouldn't've\": \"should not have\",\n    \"so've\": \"so have\",\n    \"so's\": \"so as\",\n    \"this's\": \"this is\",\n    \"that'd\": \"that would\",\n    \"that'd've\": \"that would have\",\n    \"that's\": \"that is\",\n    \"there'd\": \"there would\",\n    \"there'd've\": \"there would have\",\n    \"there's\": \"there is\",\n    \"here's\": \"here is\",\n    \"they'd\": \"they would\",\n    \"they'd've\": \"they would have\",\n    \"they'll\": \"they will\",\n    \"they'll've\": \"they will have\",\n    \"they're\": \"they are\",\n    \"they've\": \"they have\",\n    \"to've\": \"to have\",\n    \"wasn't\": \"was not\",\n    \"we'd\": \"we would\",\n    \"we'd've\": \"we would have\",\n    \"we'll\": \"we will\",\n    \"we'll've\": \"we will have\",\n    \"we're\": \"we are\",\n    \"we've\": \"we have\",\n    \"weren't\": \"were not\",\n    \"what'll\": \"what will\",\n    \"what'll've\": \"what will have\",\n    \"what're\": \"what are\",\n    \"what's\": \"what is\",\n    \"what've\": \"what have\",\n    \"when's\": \"when is\",\n    \"when've\": \"when have\",\n    \"where'd\": \"where did\",\n    \"where's\": \"where is\",\n    \"where've\": \"where have\",\n    \"who'll\": \"who will\",\n    \"who'll've\": \"who will have\",\n    \"who's\": \"who is\",\n    \"who've\": \"who have\",\n    \"why's\": \"why is\",\n    \"why've\": \"why have\",\n    \"will've\": \"will have\",\n    \"won't\": \"will not\",\n    \"won't've\": \"will not have\",\n    \"would've\": \"would have\",\n    \"wouldn't\": \"would not\",\n    \"wouldn't've\": \"would not have\",\n    \"y'all\": \"you all\",\n    \"y'all'd\": \"you all would\",\n    \"y'all'd've\": \"you all would have\",\n    \"y'all're\": \"you all are\",\n    \"y'all've\": \"you all have\",\n    \"you'd\": \"you would\",\n    \"you'd've\": \"you would have\",\n    \"you'll\": \"you will\",\n    \"you'll've\": \"you will have\",\n    \"you're\": \"you are\",\n    \"you've\": \"you have\",\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:28:36.540495Z","iopub.execute_input":"2022-04-23T17:28:36.540801Z","iopub.status.idle":"2022-04-23T17:28:36.556537Z","shell.execute_reply.started":"2022-04-23T17:28:36.540768Z","shell.execute_reply":"2022-04-23T17:28:36.555656Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class TextTransform:\n    def __call__(self, text: str) -> str:\n        return text\n\n\nclass WordTransform(TextTransform):\n    delimiter = ' '\n\n    def __call__(self, text: str) -> str:\n        words = text.split(self.delimiter)\n        result = (\n            self.transform_word(word)\n            for word in words\n        )\n        return self.delimiter.join([\n            word\n            for word in result\n            if word\n        ])\n        \n    def transform_word(self, word: str) -> str:\n        return word\n\n    \nclass LowerTransform(TextTransform):\n    def __call__(self, text: str) -> str:\n        return text.lower()\n\n\nclass TrimTransform(TextTransform):\n    def __call__(self, text: str) -> str:\n        return text.strip()\n\n    \nclass ReplaceWordTransform(WordTransform):\n    def __init__(self, items: Dict[str, str]):\n        self.items = items\n    \n    def transform_word(self, word: str) -> str:\n        return self.items.get(word, word)\n\n\nimport re\nclass RegexpWordTransform(WordTransform):\n    def __init__(self, pattern: str, to: str = ''):\n        self.pattern = re.compile(pattern)\n        self.to = to\n\n    def transform_word(self, word: str) -> str:\n        return self.pattern.sub(self.to, word)\n\n\nfrom urllib.parse import urlparse\nclass DropUrlTransform(WordTransform):\n    def transform_word(self, word: str) -> str:\n        if self.is_url(word):\n            return ''\n        return word\n\n    def is_url(self, word: str) -> bool:\n        try:\n            result = urlparse(word)\n            return all([result.scheme, result.netloc])\n        except:\n            return False\n\n\nclass TextTransformComposition(TextTransform):\n    def __init__(self, items: List[TextTransform]):\n        self.items = items\n\n    def __call__(self, text: str) -> str:\n        result = text\n        for t in self.items:\n            result = t(result)\n        return result\n","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:28:39.044624Z","iopub.execute_input":"2022-04-23T17:28:39.045195Z","iopub.status.idle":"2022-04-23T17:28:39.059662Z","shell.execute_reply.started":"2022-04-23T17:28:39.045156Z","shell.execute_reply":"2022-04-23T17:28:39.058808Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"transform = TextTransformComposition([\n    LowerTransform(),\n    DropUrlTransform(),\n    ReplaceWordTransform(replacement_dict),\n    RegexpWordTransform(r'#[\\w\\d_]+'), # hashtag remover\n    TrimTransform(),\n    LowerTransform(),\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:28:57.845884Z","iopub.execute_input":"2022-04-23T17:28:57.846667Z","iopub.status.idle":"2022-04-23T17:28:57.850641Z","shell.execute_reply.started":"2022-04-23T17:28:57.846627Z","shell.execute_reply":"2022-04-23T17:28:57.850005Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"See how `transform` works on sample of text from dataset","metadata":{}},{"cell_type":"code","source":"text = df_train.iloc[7, 0]\n\nprint(f':::{text}:::')\nprint(f':::{transform(text)}:::')","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:29:31.065459Z","iopub.execute_input":"2022-04-23T17:29:31.065716Z","iopub.status.idle":"2022-04-23T17:29:31.071498Z","shell.execute_reply.started":"2022-04-23T17:29:31.065687Z","shell.execute_reply":"2022-04-23T17:29:31.070661Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Apply text tranform to datasets","metadata":{}},{"cell_type":"code","source":"df_train['Text'] = df_train['Text'].apply(transform)\ndf_test['Text'] = df_test['Text'].apply(transform)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:29:41.704493Z","iopub.execute_input":"2022-04-23T17:29:41.705168Z","iopub.status.idle":"2022-04-23T17:29:53.225711Z","shell.execute_reply.started":"2022-04-23T17:29:41.705129Z","shell.execute_reply":"2022-04-23T17:29:53.224906Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(\n    df_train['Text'],\n    df_train['Sentiment'],\n    stratify=df_train['Sentiment'],\n    test_size=0.2,\n    random_state=SEED,\n)\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:51:31.705879Z","iopub.execute_input":"2022-04-23T17:51:31.706390Z","iopub.status.idle":"2022-04-23T17:51:31.771005Z","shell.execute_reply.started":"2022-04-23T17:51:31.706353Z","shell.execute_reply":"2022-04-23T17:51:31.770310Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\ntokenizer.fit_on_texts(list(X_train) + list(X_val) + list(df_test['Text']))\n\nX_train = tokenizer.texts_to_sequences(X_train)\nX_val = tokenizer.texts_to_sequences(X_val)\nX_test = tokenizer.texts_to_sequences(df_test['Text'])","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:51:34.008894Z","iopub.execute_input":"2022-04-23T17:51:34.009449Z","iopub.status.idle":"2022-04-23T17:51:36.832077Z","shell.execute_reply.started":"2022-04-23T17:51:34.009412Z","shell.execute_reply":"2022-04-23T17:51:36.831314Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"all_texts = pd.concat([df_train['Text'], df_test['Text']], axis=0)\nlens = all_texts.apply(lambda s: len(s))\nlens.plot.hist(bins=50)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:30:01.235353Z","iopub.execute_input":"2022-04-23T17:30:01.235610Z","iopub.status.idle":"2022-04-23T17:30:01.549562Z","shell.execute_reply.started":"2022-04-23T17:30:01.235580Z","shell.execute_reply":"2022-04-23T17:30:01.548886Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"MAX_TEXT_LEN = 355\n\nX_train = pad_sequences(X_train, maxlen=MAX_TEXT_LEN)\nX_val = pad_sequences(X_val, maxlen=MAX_TEXT_LEN)\nX_test = pad_sequences(X_test, maxlen=MAX_TEXT_LEN)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:51:40.355738Z","iopub.execute_input":"2022-04-23T17:51:40.356300Z","iopub.status.idle":"2022-04-23T17:51:40.622478Z","shell.execute_reply.started":"2022-04-23T17:51:40.356258Z","shell.execute_reply":"2022-04-23T17:51:40.621784Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\ny_train = le.fit_transform(y_train.values)\ny_val = le.transform(y_val.values)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:51:43.413524Z","iopub.execute_input":"2022-04-23T17:51:43.414139Z","iopub.status.idle":"2022-04-23T17:51:43.428852Z","shell.execute_reply.started":"2022-04-23T17:51:43.414099Z","shell.execute_reply":"2022-04-23T17:51:43.427964Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"Load and setup Glove embeddings","metadata":{}},{"cell_type":"code","source":"!wget http://nlp.stanford.edu/data/glove.840B.300d.zip\n!unzip glove.840B.300d.zip","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:30:11.430811Z","iopub.execute_input":"2022-04-23T17:30:11.431139Z","iopub.status.idle":"2022-04-23T17:39:26.965562Z","shell.execute_reply.started":"2022-04-23T17:30:11.431101Z","shell.execute_reply":"2022-04-23T17:39:26.964667Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"## FUNCTION FROM https://www.kaggle.com/gmhost/gru-capsule\n\ndef load_glove(word_index):\n    EMBEDDING_FILE = 'glove.840B.300d.txt'\n    def get_coefs(word,*arr):\n        return word, np.asarray(arr, dtype='float32')[:300]\n    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n    \n    all_embs = np.stack(embeddings_index.values())\n    emb_mean,emb_std = -0.005838499,0.48782197\n    embed_size = all_embs.shape[1]\n\n    nb_words = min(MAX_VOCAB_SIZE, len(word_index)+1)\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n    for word, i in word_index.items():\n        if i >= MAX_VOCAB_SIZE: continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None: \n            embedding_matrix[i] = embedding_vector\n        else:\n            embedding_vector = embeddings_index.get(word.capitalize())\n            if embedding_vector is not None: \n                embedding_matrix[i] = embedding_vector\n    return embedding_matrix","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:40:38.249309Z","iopub.execute_input":"2022-04-23T17:40:38.249610Z","iopub.status.idle":"2022-04-23T17:40:38.260642Z","shell.execute_reply.started":"2022-04-23T17:40:38.249578Z","shell.execute_reply":"2022-04-23T17:40:38.259893Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"embedding_matrix = load_glove(tokenizer.word_index)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:40:45.356014Z","iopub.execute_input":"2022-04-23T17:40:45.356726Z","iopub.status.idle":"2022-04-23T17:43:32.739194Z","shell.execute_reply.started":"2022-04-23T17:40:45.356686Z","shell.execute_reply":"2022-04-23T17:43:32.738411Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class BiLSTM(nn.Module):\n    def __init__(self, embedding_matrix, num_classes: int, dropout: float):\n        super(BiLSTM, self).__init__()\n        max_features, embed_size = embedding_matrix.shape\n        self.hidden_size = 64\n        self.embedding = nn.Embedding(max_features, embed_size)\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n        self.embedding.weight.requires_grad = False\n        self.lstm = nn.LSTM(embed_size, self.hidden_size, bidirectional=True, batch_first=True)\n        self.linear = nn.Linear(self.hidden_size*4 , 64)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n        self.out = nn.Linear(64, num_classes)\n\n    def forward(self, x):\n        h_embedding = self.embedding(x)\n        h_lstm, _ = self.lstm(h_embedding)\n        avg_pool = torch.mean(h_lstm, 1)\n        max_pool, _ = torch.max(h_lstm, 1)\n        conc = torch.cat(( avg_pool, max_pool), 1)\n        conc = self.relu(self.linear(conc))\n        conc = self.dropout(conc)\n        out = self.out(conc)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:44:06.843344Z","iopub.execute_input":"2022-04-23T17:44:06.843607Z","iopub.status.idle":"2022-04-23T17:44:06.852547Z","shell.execute_reply.started":"2022-04-23T17:44:06.843577Z","shell.execute_reply":"2022-04-23T17:44:06.851915Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model = BiLSTM(embedding_matrix, num_classes=len(le.classes_), dropout=0.2)\nloss_fn = nn.CrossEntropyLoss(reduction='sum')\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:50:25.625896Z","iopub.execute_input":"2022-04-23T17:50:25.626611Z","iopub.status.idle":"2022-04-23T17:50:25.767109Z","shell.execute_reply.started":"2022-04-23T17:50:25.626571Z","shell.execute_reply":"2022-04-23T17:50:25.766396Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else  torch.device('cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:50:27.695334Z","iopub.execute_input":"2022-04-23T17:50:27.695730Z","iopub.status.idle":"2022-04-23T17:50:27.701758Z","shell.execute_reply.started":"2022-04-23T17:50:27.695694Z","shell.execute_reply":"2022-04-23T17:50:27.701122Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:50:32.129666Z","iopub.execute_input":"2022-04-23T17:50:32.130102Z","iopub.status.idle":"2022-04-23T17:50:32.159567Z","shell.execute_reply.started":"2022-04-23T17:50:32.130061Z","shell.execute_reply":"2022-04-23T17:50:32.158903Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Load train and test in CUDA Memory\nX_train = torch.tensor(X_train, dtype=torch.long).to(device)\ny_train = torch.tensor(y_train, dtype=torch.long).to(device)\nX_val = torch.tensor(X_val, dtype=torch.long).to(device)\ny_val = torch.tensor(y_val, dtype=torch.long).to(device)\nX_test = torch.tensor(X_test, dtype=torch.long).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:51:52.769579Z","iopub.execute_input":"2022-04-23T17:51:52.769830Z","iopub.status.idle":"2022-04-23T17:51:52.823606Z","shell.execute_reply.started":"2022-04-23T17:51:52.769800Z","shell.execute_reply":"2022-04-23T17:51:52.822944Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Create Torch datasets\ntrain = torch.utils.data.TensorDataset(X_train, y_train)\nvalid = torch.utils.data.TensorDataset(X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:51:59.123062Z","iopub.execute_input":"2022-04-23T17:51:59.123461Z","iopub.status.idle":"2022-04-23T17:51:59.130564Z","shell.execute_reply.started":"2022-04-23T17:51:59.123430Z","shell.execute_reply":"2022-04-23T17:51:59.129864Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Create Data Loaders\ntrain_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:51:59.661550Z","iopub.execute_input":"2022-04-23T17:51:59.662094Z","iopub.status.idle":"2022-04-23T17:51:59.666642Z","shell.execute_reply.started":"2022-04-23T17:51:59.662056Z","shell.execute_reply":"2022-04-23T17:51:59.665817Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"train_loss = []\nvalid_loss = []\n\nn_epochs = 3 # Если сделать больше, не сохранится версия: нет GPU и учится слишком долго.\n\nfor epoch in range(n_epochs):\n    start_time = time.time()\n    # Set model to train configuration\n    model.train()\n    avg_loss = 0.  \n    for i, (x_batch, y_batch) in enumerate(train_loader):\n        # Predict/Forward Pass\n        y_pred = model(x_batch)\n        # Compute loss\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        avg_loss += loss.item() / len(train_loader)\n    \n    # Set model to validation configuration -Doesn't get trained here\n    model.eval()\n    avg_val_loss = 0.\n    val_preds = np.zeros((len(X_val), len(le.classes_)))\n    for i, (x_batch, y_batch) in enumerate(valid_loader):\n        y_pred = model(x_batch).detach()\n        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n        # keep/store predictions\n        val_preds[i * BATCH_SIZE : (i+1) * BATCH_SIZE] = F.softmax(y_pred).cpu().numpy()\n    \n    # Check Accuracy\n    val_preds_tensor = torch.tensor(val_preds.argmax(axis=1)).to(device)\n    val_accuracy = sum(torch.eq(val_preds_tensor, y_val)) / len(y_val)\n    train_loss.append(avg_loss)\n    valid_loss.append(avg_val_loss)\n    elapsed_time = time.time() - start_time \n    print(f'Epoch {epoch + 1}/{n_epochs} \\t loss={avg_loss:.4f} \\t val_loss={avg_val_loss:.4f}  \\t val_acc={val_accuracy:.4f}  \\t time={elapsed_time:.2f}s')","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:56:39.981640Z","iopub.execute_input":"2022-04-23T17:56:39.982412Z","iopub.status.idle":"2022-04-23T17:57:30.770023Z","shell.execute_reply.started":"2022-04-23T17:56:39.982367Z","shell.execute_reply":"2022-04-23T17:57:30.769288Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def plot_graph(epochs):\n    fig = plt.figure(figsize=(12,12))\n    plt.title(\"Train/Validation Loss\")\n    plt.plot(list(np.arange(epochs) + 1) , train_loss, label='train')\n    plt.plot(list(np.arange(epochs) + 1), valid_loss, label='validation')\n    plt.xlabel('num_epochs', fontsize=12)\n    plt.ylabel('loss', fontsize=12)\n    plt.legend(loc='best')","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:57:52.237823Z","iopub.execute_input":"2022-04-23T17:57:52.238111Z","iopub.status.idle":"2022-04-23T17:57:52.245683Z","shell.execute_reply.started":"2022-04-23T17:57:52.238077Z","shell.execute_reply":"2022-04-23T17:57:52.244706Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"plot_graph(n_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:58:10.541874Z","iopub.execute_input":"2022-04-23T17:58:10.542444Z","iopub.status.idle":"2022-04-23T17:58:10.790491Z","shell.execute_reply.started":"2022-04-23T17:58:10.542408Z","shell.execute_reply":"2022-04-23T17:58:10.789828Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"A bit of overfitting (","metadata":{}},{"cell_type":"code","source":"y_true = [le.classes_[x] for x in y_val]\ny_pred = [le.classes_[x] for x in val_preds.argmax(axis=1)]\nskplt.metrics.plot_confusion_matrix(\n    y_true, \n    y_pred,\n    figsize=(12,12),x_tick_rotation=90)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:58:59.729016Z","iopub.execute_input":"2022-04-23T17:58:59.729588Z","iopub.status.idle":"2022-04-23T17:59:00.212425Z","shell.execute_reply.started":"2022-04-23T17:58:59.729548Z","shell.execute_reply":"2022-04-23T17:59:00.211771Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"df_submission = pd.read_csv(DATA_PATH / 'sample_submission.csv')\ndf_submission.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:59:47.122821Z","iopub.execute_input":"2022-04-23T17:59:47.123603Z","iopub.status.idle":"2022-04-23T17:59:47.140882Z","shell.execute_reply.started":"2022-04-23T17:59:47.123563Z","shell.execute_reply":"2022-04-23T17:59:47.140156Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"pred = model(X_test).detach()\npred = F.softmax(pred).cpu().numpy()\npred = pred.argmax(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T18:00:33.274549Z","iopub.execute_input":"2022-04-23T18:00:33.275012Z","iopub.status.idle":"2022-04-23T18:00:33.408446Z","shell.execute_reply.started":"2022-04-23T18:00:33.274954Z","shell.execute_reply":"2022-04-23T18:00:33.407719Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"df_submission['Sentiment'] = le.classes_[pred]\ndf_submission.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T18:00:39.881259Z","iopub.execute_input":"2022-04-23T18:00:39.881638Z","iopub.status.idle":"2022-04-23T18:00:39.891703Z","shell.execute_reply.started":"2022-04-23T18:00:39.881598Z","shell.execute_reply":"2022-04-23T18:00:39.890852Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"df_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T18:01:02.195490Z","iopub.execute_input":"2022-04-23T18:01:02.195743Z","iopub.status.idle":"2022-04-23T18:01:02.215881Z","shell.execute_reply.started":"2022-04-23T18:01:02.195713Z","shell.execute_reply":"2022-04-23T18:01:02.215229Z"},"trusted":true},"execution_count":70,"outputs":[]}]}